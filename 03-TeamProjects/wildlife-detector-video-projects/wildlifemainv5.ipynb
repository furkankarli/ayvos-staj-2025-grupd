{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f310b092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T11:23:21.557755Z",
     "iopub.status.busy": "2025-08-07T11:23:21.557464Z",
     "iopub.status.idle": "2025-08-07T11:24:40.167311Z",
     "shell.execute_reply": "2025-08-07T11:24:40.166457Z"
    },
    "executionInfo": {
     "elapsed": 119120,
     "status": "ok",
     "timestamp": 1754560994856,
     "user": {
      "displayName": "Göktan İren",
      "userId": "05123232311365943132"
     },
     "user_tz": -180
    },
    "id": "cQcH7UDrwOt3",
    "outputId": "5a40e1b9-c6bc-4557-9a91-6c67a7de3270",
    "papermill": {
     "duration": 78.61527,
     "end_time": "2025-08-07T11:24:40.168849",
     "exception": false,
     "start_time": "2025-08-07T11:23:21.553579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\r\n",
      "Collecting segment-anything-py\r\n",
      "  Downloading segment_anything_py-1.0.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting open-clip-torch\r\n",
      "  Downloading open_clip_torch-3.1.0-py3-none-any.whl.metadata (32 kB)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2024.11.6)\r\n",
      "Collecting ftfy (from open-clip-torch)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (4.67.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.33.1)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.5.3)\r\n",
      "Collecting timm>=1.0.17 (from open-clip-torch)\r\n",
      "  Downloading timm-1.0.19-py3-none-any.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=1.0.17->open-clip-torch) (6.0.2)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch) (0.2.13)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (2.32.4)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (1.1.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading segment_anything_py-1.0.1-py3-none-any.whl (40 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading open_clip_torch-3.1.0-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-1.0.19-py3-none-any.whl (2.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm, segment-anything-py, open-clip-torch\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.15\r\n",
      "    Uninstalling timm-1.0.15:\r\n",
      "      Successfully uninstalled timm-1.0.15\r\n",
      "Successfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open-clip-torch-3.1.0 segment-anything-py-1.0.1 timm-1.0.19\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python torch torchvision matplotlib segment-anything-py open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d276e4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T11:24:40.217965Z",
     "iopub.status.busy": "2025-08-07T11:24:40.217700Z",
     "iopub.status.idle": "2025-08-07T11:27:15.230634Z",
     "shell.execute_reply": "2025-08-07T11:27:15.229629Z"
    },
    "id": "8C0tnEQXvNYs",
    "outputId": "6e73fd6f-109f-4f18-8202-046f7e4e04c6",
    "papermill": {
     "duration": 155.039141,
     "end_time": "2025-08-07T11:27:15.231867",
     "exception": false,
     "start_time": "2025-08-07T11:24:40.192726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4644fbae4524f65a9f9cd909020a6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/open_clip/factory.py:450: UserWarning: QuickGELU mismatch between final model config (quick_gelu=False) and pretrained tag 'openai' (quick_gelu=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame 1\n",
      "Processed frame 2\n",
      "Processed frame 3\n",
      "Processed frame 4\n",
      "Processed frame 5\n",
      "Processed frame 6\n",
      "Processed frame 7\n",
      "Processed frame 8\n",
      "Processed frame 9\n",
      "Processed frame 10\n",
      "Processed frame 11\n",
      "Processed frame 12\n",
      "Processed frame 13\n",
      "Processed frame 14\n",
      "Processed frame 15\n",
      "Processed frame 16\n",
      "Processed frame 17\n",
      "Processed frame 18\n",
      "Processed frame 19\n",
      "Processed frame 20\n",
      "Processed frame 21\n",
      "Processed frame 22\n",
      "Processed frame 23\n",
      "Processed frame 24\n",
      "Processed frame 25\n",
      "Processed frame 26\n",
      "Processed frame 27\n",
      "Processed frame 28\n",
      "Processed frame 29\n",
      "Processed frame 30\n",
      "Processed frame 31\n",
      "Processed frame 32\n",
      "Processed frame 33\n",
      "Processed frame 34\n",
      "Processed frame 35\n",
      "Processed frame 36\n",
      "Processed frame 37\n",
      "Processed frame 38\n",
      "Processed frame 39\n",
      "Processed frame 40\n",
      "Processed frame 41\n",
      "Processed frame 42\n",
      "Processed frame 43\n",
      "Processed frame 44\n",
      "Processed frame 45\n",
      "Processed frame 46\n",
      "Processed frame 47\n",
      "Processed frame 48\n",
      "Processed frame 49\n",
      "Processed frame 50\n",
      "Processed frame 51\n",
      "Processed frame 52\n",
      "Processed frame 53\n",
      "Processed frame 54\n",
      "Processed frame 55\n",
      "Processed frame 56\n",
      "Processed frame 57\n",
      "Processed frame 58\n",
      "Processed frame 59\n",
      "Processed frame 60\n",
      "Processed frame 61\n",
      "Processed frame 62\n",
      "Processed frame 63\n",
      "Processed frame 64\n",
      "Processed frame 65\n",
      "Processed frame 66\n",
      "Processed frame 67\n",
      "Processed frame 68\n",
      "Processed frame 69\n",
      "Processed frame 70\n",
      "Processed frame 71\n",
      "Processed frame 72\n",
      "Processed frame 73\n",
      "Processed frame 74\n",
      "Processed frame 75\n",
      "Processed frame 76\n",
      "Processed frame 77\n",
      "Processed frame 78\n",
      "Processed frame 79\n",
      "Processed frame 80\n",
      "Processed frame 81\n",
      "Processed frame 82\n",
      "Processed frame 83\n",
      "Processed frame 84\n",
      "Processed frame 85\n",
      "Processed frame 86\n",
      "Processed frame 87\n",
      "Processed frame 88\n",
      "Processed frame 89\n",
      "Processed frame 90\n",
      "Processed frame 91\n",
      "Processed frame 92\n",
      "Processed frame 93\n",
      "Processed frame 94\n",
      "Processed frame 95\n",
      "Processed frame 96\n",
      "Processed frame 97\n",
      "Processed frame 98\n",
      "Processed frame 99\n",
      "Processed frame 100\n",
      "Processed frame 101\n",
      "Processed frame 102\n",
      "Processed frame 103\n",
      "Processed frame 104\n",
      "Processed frame 105\n",
      "Processed frame 106\n",
      "Processed frame 107\n",
      "Processed frame 108\n",
      "Processed frame 109\n",
      "Processed frame 110\n",
      "Processed frame 111\n",
      "Processed frame 112\n",
      "Processed frame 113\n",
      "Processed frame 114\n",
      "Processed frame 115\n",
      "Processed frame 116\n",
      "Processed frame 117\n",
      "Processed frame 118\n",
      "Processed frame 119\n",
      "Processed frame 120\n",
      "Processed frame 121\n",
      "Processed frame 122\n",
      "Processed frame 123\n",
      "Processed frame 124\n",
      "Processed frame 125\n",
      "Processed frame 126\n",
      "Processed frame 127\n",
      "Processed frame 128\n",
      "Processed frame 129\n",
      "Processed frame 130\n",
      "Processed frame 131\n",
      "Processed frame 132\n",
      "Processed frame 133\n",
      "Processed frame 134\n",
      "Processed frame 135\n",
      "Processed frame 136\n",
      "Processed frame 137\n",
      "Processed frame 138\n",
      "Processed frame 139\n",
      "Processed frame 140\n",
      "Processed frame 141\n",
      "Processed frame 142\n",
      "Processed frame 143\n",
      "Processed frame 144\n",
      "Processed frame 145\n",
      "Processed frame 146\n",
      "Processed frame 147\n",
      "Processed frame 148\n",
      "Processed frame 149\n",
      "Processed frame 150\n",
      "Processed frame 151\n",
      "Processed frame 152\n",
      "Processed frame 153\n",
      "Processed frame 154\n",
      "Processed frame 155\n",
      "Processed frame 156\n",
      "Processed frame 157\n",
      "Processed frame 158\n",
      "Processed frame 159\n",
      "Processed frame 160\n",
      "Processed frame 161\n",
      "Processed frame 162\n",
      "Processed frame 163\n",
      "Processed frame 164\n",
      "Processed frame 165\n",
      "Processed frame 166\n",
      "Processed frame 167\n",
      "Processed frame 168\n",
      "Processed frame 169\n",
      "Processed frame 170\n",
      "Processed frame 171\n",
      "Processed frame 172\n",
      "Processed frame 173\n",
      "Processed frame 174\n",
      "Processed frame 175\n",
      "Processed frame 176\n",
      "Processed frame 177\n",
      "Processed frame 178\n",
      "Processed frame 179\n",
      "Processed frame 180\n",
      "Processed frame 181\n",
      "Processed frame 182\n",
      "Processed frame 183\n",
      "Processed frame 184\n",
      "Processed frame 185\n",
      "Processed frame 186\n",
      "Processed frame 187\n",
      "Processed frame 188\n",
      "Processed frame 189\n",
      "Processed frame 190\n",
      "Processed frame 191\n",
      "Processed frame 192\n",
      "Processed frame 193\n",
      "Processed frame 194\n",
      "Processed frame 195\n",
      "Processed frame 196\n",
      "Processed frame 197\n",
      "Processed frame 198\n",
      "Processed frame 199\n",
      "Processed frame 200\n",
      "Processed frame 201\n",
      "Processed frame 202\n",
      "Processed frame 203\n",
      "Processed frame 204\n",
      "Processed frame 205\n",
      "Processed frame 206\n",
      "Processed frame 207\n",
      "Processed frame 208\n",
      "Processed frame 209\n",
      "Processed frame 210\n",
      "Processed frame 211\n",
      "Processed frame 212\n",
      "Processed frame 213\n",
      "Processed frame 214\n",
      "Processed frame 215\n",
      "Processed frame 216\n",
      "Processed frame 217\n",
      "Processed frame 218\n",
      "Processed frame 219\n",
      "Processed frame 220\n",
      "Processed frame 221\n",
      "Processed frame 222\n",
      "Processed frame 223\n",
      "Processed frame 224\n",
      "Processed frame 225\n",
      "Processed frame 226\n",
      "Processed frame 227\n",
      "Processed frame 228\n",
      "Processed frame 229\n",
      "Processed frame 230\n",
      "Processed frame 231\n",
      "Processed frame 232\n",
      "Processed frame 233\n",
      "Processed frame 234\n",
      "Processed frame 235\n",
      "Processed frame 236\n",
      "Processed frame 237\n",
      "Processed frame 238\n",
      "Processed frame 239\n",
      "Processed frame 240\n",
      "Processed frame 241\n",
      "Processed frame 242\n",
      "Processed frame 243\n",
      "Processed frame 244\n",
      "Processed frame 245\n",
      "Processed frame 246\n",
      "Processed frame 247\n",
      "Processed frame 248\n",
      "Processed frame 249\n",
      "Processed frame 250\n",
      "Processed frame 251\n",
      "Processed frame 252\n",
      "Processed frame 253\n",
      "Processed frame 254\n",
      "✅ Video processing complete. Output saved to output_video.mp4 and video_log.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from open_clip import create_model_and_transforms, get_tokenizer\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Load SAM model\n",
    "# ------------------------------\n",
    "sam_checkpoint = \"/kaggle/input/sam_vit_b/other/default/1/sam_vit_b.pth\"\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=sam_checkpoint)\n",
    "sam.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Load OpenCLIP model\n",
    "# ------------------------------\n",
    "model, _, preprocess = create_model_and_transforms(\"ViT-B-32\", pretrained=\"openai\")\n",
    "model.eval()\n",
    "model.cuda() if torch.cuda.is_available() else model.cpu()\n",
    "tokenizer = get_tokenizer(\"ViT-B-32\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Define candidate labels\n",
    "# ------------------------------\n",
    "candidate_labels =[\"a dog\", \"a goat\", \"a panda\", \"a cat\"]\n",
    "text_tokens = tokenizer(candidate_labels).cuda() if torch.cuda.is_available() else tokenizer(candidate_labels)\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Start video processing\n",
    "# ------------------------------\n",
    "video_path = \"/kaggle/input/sam_vit_b/other/default/1/input_videov3.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(\"/kaggle/working/output.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# ------------------------------\n",
    "# 5. CSV logging\n",
    "# ------------------------------\n",
    "csvfile = open(\"/kaggle/working/video_logv3.csv\", \"w\", newline=\"\")\n",
    "csvwriter = csv.writer(csvfile)\n",
    "csvwriter.writerow([\"frame_id\", \"label\", \"confidence\", \"x\", \"y\", \"w\", \"h\"])\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Frame-by-frame loop\n",
    "# ------------------------------\n",
    "frame_id = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_id += 1\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    predictor.set_image(image_rgb)\n",
    "    image_tensor = torch.tensor(image_rgb).permute(2, 0, 1).contiguous()\n",
    "    image_tensor = image_tensor.cuda() if torch.cuda.is_available() else image_tensor\n",
    "\n",
    "    H, W = image_rgb.shape[:2]\n",
    "    input_box = np.array([0, 0, W, H])  # entire image\n",
    "    masks, scores, logits = predictor.predict(box=input_box[None, :], multimask_output=True)\n",
    "\n",
    "    animal_count = 0  # to keep track of the number of animals in each square\n",
    "\n",
    "    for i, mask in enumerate(masks):\n",
    "        area = np.sum(mask)\n",
    "        if area < 5000:  # filter small segments\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))\n",
    "        cropped = image_rgb[y:y+h, x:x+w]\n",
    "        pil_crop = Image.fromarray(cropped)\n",
    "        image_input = preprocess(pil_crop).unsqueeze(0)\n",
    "        image_input = image_input.cuda() if torch.cuda.is_available() else image_input\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image_input)\n",
    "            text_features = model.encode_text(text_tokens)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            similarity = (image_features @ text_features.T).squeeze(0)\n",
    "\n",
    "        best_idx = similarity.argmax().item()\n",
    "        best_label = candidate_labels[best_idx]\n",
    "        best_score = similarity[best_idx].item()\n",
    "\n",
    "        animal_count += 1\n",
    "\n",
    "        # Draw on frame\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        label_text = f\"{best_label} ({best_score:.2f})\"\n",
    "        cv2.putText(frame, label_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "\n",
    "        # Log to CSV\n",
    "        csvwriter.writerow([frame_id, best_label, round(best_score, 3), x, y, w, h])\n",
    "    \n",
    "    # Add animal count text to the frame\n",
    "    cv2.putText(frame, f\"Animals detected: {animal_count}\", (20, 40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    out.write(frame)\n",
    "    print(f\"Processed frame {frame_id}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Cleanup\n",
    "# ------------------------------\n",
    "cap.release()\n",
    "out.release()\n",
    "csvfile.close()\n",
    "print(\"✅ Video processing complete. Output saved to output_video.mp4 and video_log.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 422705,
     "modelInstanceId": 404803,
     "sourceId": 511036,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 240.244872,
   "end_time": "2025-08-07T11:27:17.446412",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-07T11:23:17.201540",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0895b2391689485abb526596d7f5d21a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "21e770d5f0864cdfbefcc9862c3fb56f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31154795363e4b67941c0af85e1059ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_21e770d5f0864cdfbefcc9862c3fb56f",
       "max": 605143284.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8ac13337976c4e72a2a07d31de2a24e1",
       "tabbable": null,
       "tooltip": null,
       "value": 605143284.0
      }
     },
     "48605b53c5c94833ba5f1869925c878a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59212b9526524968af638c845542d3a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82b2d8ec6858414898d0e5a7816527a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59212b9526524968af638c845542d3a3",
       "placeholder": "​",
       "style": "IPY_MODEL_0895b2391689485abb526596d7f5d21a",
       "tabbable": null,
       "tooltip": null,
       "value": " 605M/605M [00:02&lt;00:00, 256MB/s]"
      }
     },
     "8ac13337976c4e72a2a07d31de2a24e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9fd9c4584f8c4bf39e510def8f986443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_db85f82e90a54dbab1c2bbf64a89c921",
       "placeholder": "​",
       "style": "IPY_MODEL_f045b495132e43e2adb1764426c1d1e9",
       "tabbable": null,
       "tooltip": null,
       "value": "open_clip_model.safetensors: 100%"
      }
     },
     "d4644fbae4524f65a9f9cd909020a6e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9fd9c4584f8c4bf39e510def8f986443",
        "IPY_MODEL_31154795363e4b67941c0af85e1059ee",
        "IPY_MODEL_82b2d8ec6858414898d0e5a7816527a6"
       ],
       "layout": "IPY_MODEL_48605b53c5c94833ba5f1869925c878a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "db85f82e90a54dbab1c2bbf64a89c921": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f045b495132e43e2adb1764426c1d1e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
