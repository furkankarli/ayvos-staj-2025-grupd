# Wildlife Detector in Videos and Images

A deep learning pipeline for detecting, segmenting, and classifying animals in both images and videos. It uses Meta AI's **SAM (Segment Anything Model)** for segmentation and **OpenCLIP** for zero-shot classification. The final output includes annotated images or videos, along with CSV logs of detections and real-time animal counts in videos.

---

## ğŸ§  Model Overview

- **SAM (Segment Anything Model)** is used to generate segmentation masks:
  - `sam_vit_h_4b8939.pth`: for image-based segmentation (not uploaded to GitHub).
  - `sam_vit_b.pth`: for real-time video segmentation.
- **OpenCLIP** is used to classify each segmented region based on cosine similarity between image and text embeddings.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/                      # 10 sample images for testing
â”‚
â”œâ”€â”€ models/                   # Pretrained SAM models
â”‚   â”œâ”€â”€ sam_vit_b.pth         # Used in video processing
â”‚   â””â”€â”€ sam_vit_h_4b8939.pth  # Used in image segmentation (not included in repo)
â”‚
â”œâ”€â”€ outputs/                  # Image segmentation results from segment.py
â”œâ”€â”€ outputs_classified/      # Image classification results from classify.py
â”œâ”€â”€ outputs_classifiedv2/    # Refined image classification results from classifyv2.py
â”œâ”€â”€ segments/                # Segmentation masks for classifyv2.py
â”‚
â”œâ”€â”€ log.csv                  # Log from classifyv2.py
â”œâ”€â”€ video_log.csv            # Log from classify_video.py
â”‚
â”œâ”€â”€ input_video.mp4          # Original test video
â”œâ”€â”€ input_videov1.mp4        # Additional video sample
â”œâ”€â”€ input_videov2.mp4
â”œâ”€â”€ input_videov3.mp4
â”œâ”€â”€ input_videov5.mp4
â”‚
â”œâ”€â”€ video_log.csv         # Frame-by-frame detection logs.
â”œâ”€â”€ video_logv2.csv
â”œâ”€â”€ video_logv3.csv
â”œâ”€â”€ video_logv5.csv
â”‚
â”œâ”€â”€ output_video.mp4         # Output with detection overlays
â”œâ”€â”€ output_videov1.mp4
â”œâ”€â”€ output_videov2.mp4
â”œâ”€â”€ output_videov3.mp4
â”œâ”€â”€ output_videov5.mp4
â”‚
â”œâ”€â”€ segment.py               # Segments animals in images using SAM
â”œâ”€â”€ classify.py              # Classifies animals in images using OpenCLIP
â”œâ”€â”€ classifyv2.py            # Filters by confidence + segments + classifies
â”œâ”€â”€ classify_video.py        # Full pipeline on video (SAM + OpenCLIP + CSV)
â”‚
â”œâ”€â”€ wildlifemainv0.ipynb     # Colab version (input_video.mp4 -> output_video.mp4)
â”œâ”€â”€ wildlifemainv1.ipynb     # Colab version for v1
â”œâ”€â”€ wildlifemainv2.ipynb     # Colab version for v2
â”œâ”€â”€ wildlifemainv3.ipynb     # Colab version for v3
â”œâ”€â”€ wildlifemainv5.ipynb     # Colab version for v4 (Shows the latest version and current animal count.)
```

---

## ğŸ› ï¸ Features

âœ… Segment animals in static images using SAM  
âœ… Classify segments using OpenCLIP (zero-shot)  
âœ… Detect animals in videos frame-by-frame  
âœ… Filter predictions by confidence threshold (â‰¥ 75%)  
âœ… Count animals in each video frame  
âœ… Log results to CSV (per frame, with coordinates and confidence)  
âœ… Output annotated videos with bounding boxes and labels

---

## ğŸ§ª Project Workflow

### 1. **Image-based Segmentation & Classification**
- Run `segment.py` to segment 10 test images in `data/`
- Then run `classify.py` or `classifyv2.py` to classify each segment using OpenCLIP
- Outputs are saved in:
  - `outputs/`
  - `outputs_classified/`
  - `outputs_classifiedv2/`

### 2. **Video-based Detection**
- Run `classify_video.py` to apply SAM + OpenCLIP on videos like `input_video.mp4`
- Frame-by-frame detection with real-time animal counting
- Output is saved as:
  - Annotated video: `output_video.mp4`
  - Log CSV: `video_log.csv`

---

## ğŸ“¦ Requirements

Install dependencies:

```bash
pip install torch torchvision
pip install opencv-python
pip install git+https://github.com/facebookresearch/segment-anything.git
pip install git+https://github.com/mlfoundations/open_clip.git
```

> ğŸ’¡ Recommended: Use Google Colab for running notebooks `wildlifemainv*.ipynb` with GPU.

---

## ğŸ§  Model Weights

| Model File              | Description                    | Download Link |
|-------------------------|--------------------------------|----------------|
| `sam_vit_h_4b8939.pth`  | Used in `segment.py` (image)   | [Download via Meta](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth) |
| `sam_vit_b.pth`         | Used in `classify_video.py`    | Included in `models/` folder |

---

## ğŸ“Š Sample Output

![sample_frame](outputs_classifiedv2/classified_01.jpg)

---

## ğŸ“ˆ Example Log (CSV)

```
frame_id,label,confidence,x,y,w,h
1,a deer,0.87,143,202,75,90
1,a fox,0.91,320,210,65,80
...
```

---

## ğŸ§ª Future Work

- Add YOLO-based fallback for faster classification
- Integrate tracking (SORT/DeepSORT) for tracking animals across frames
- Improve filtering on segmentation masks

---

## ğŸ¾ Author

Developed by GÃ¶ktan Ä°ren as a computer vision project for multi-animal detection in the wild.

---

## ğŸ“„ License

MIT License
